{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analytics workshop by Bhavik Gandhi\n",
    "\n",
    "# Brushing up NLP Basics and Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text is ubiquitous these days\n",
    "\n",
    "Text Analytics is all about analyzing text data and understanding making sense of it.\n",
    "\n",
    "Text Analytics, while is used interchangeably with NLP they are meant to be somewhat different.\n",
    "\n",
    "Text Analytics does not focus on the underlying structure of the text, the natural language behind it.\n",
    "\n",
    "Text Analytics is about analyzing words or sentences and their occurences.\n",
    "\n",
    "It is similar to building models on time series data or image data, where it understands that the unit of the data is words or characters (similar to pixels in images) but it does not attempt to understand the structure of a natural language (the grammar and the semantics). NLP attempts to do that.\n",
    "\n",
    "For instance the below sentences will be considered by text analytics to mean happiness whereas NLP will say neither of them do.\n",
    "\n",
    "1. She will be happy if she wins it.\n",
    "\n",
    "2. Is he happy with his job?\n",
    "\n",
    "3. He is not happy since a week\n",
    "\n",
    "Let's first look at some NLP, it is often used to pre-process in a text analytics problem\n",
    "\n",
    "Text is unstructured and has a lot of fillers!\n",
    "\n",
    "\"People like to see Sachin play. It always gets them interested in Cricket! It's good to see people show such interest.\"\n",
    "\n",
    "Now here words like \"to\", \"it\", \"in\", \"it's\", \"to\" do not add any value to models. So let's see what we can do about them.\n",
    "\n",
    "As they say \"your model is only as good as your data\", it is important to remove these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"People like to see Sachin play. It always gets them interested in Cricket! It's good to see people show such interest. They love Sachin. He has given so much to the game. His strokes with his MRF bat are etched in people's memoris. Many current cricketers owe pursuing cricket to him.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization\n",
    "\n",
    "Word Tokenization\n",
    "\n",
    "Also Sentence Tokenization\n",
    "\n",
    "Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['People', 'like', 'to', 'see', 'Sachin', 'play', '.', 'It', 'always', 'gets', 'them', 'interested', 'in', 'Cricket', '!', 'It', \"'s\", 'good', 'to', 'see', 'people', 'show', 'such', 'interest', '.', 'They', 'love', 'Sachin', '.', 'He', 'has', 'given', 'so', 'much', 'to', 'the', 'game', '.', 'His', 'strokes', 'with', 'his', 'MRF', 'bat', 'are', 'etched', 'in', 'people', \"'s\", 'memoris', '.', 'Many', 'current', 'cricketers', 'owe', 'pursuing', 'cricket', 'to', 'him', '.']\n",
      "['People', 'like', 'see', 'Sachin', 'play', '.', 'It', 'always', 'gets', 'interested', 'Cricket', '!', 'It', \"'s\", 'good', 'see', 'people', 'show', 'interest', '.', 'They', 'love', 'Sachin', '.', 'He', 'given', 'much', 'game', '.', 'His', 'strokes', 'MRF', 'bat', 'etched', 'people', \"'s\", 'memoris', '.', 'Many', 'current', 'cricketers', 'owe', 'pursuing', 'cricket', '.']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    " \n",
    "word_tokens = word_tokenize(text)   \n",
    "    \n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    " \n",
    "print(word_tokens)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punctuation\n",
    "\n",
    "Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['people', 'like', 'see', 'sachin', 'play', 'it', 'always', 'gets', 'interested', 'cricket', 'it', 'good', 'see', 'people', 'show', 'interest', 'they', 'love', 'sachin', 'he', 'given', 'much', 'game', 'his', 'strokes', 'mrf', 'bat', 'etched', 'people', 'memoris', 'many', 'current', 'cricketers', 'owe', 'pursuing', 'cricket']\n"
     ]
    }
   ],
   "source": [
    "words = [w.lower() for w in filtered_sentence if w.isalpha()]\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PoS Tagging\n",
    "\n",
    "Besides helping with lemmatization, they can be very useful with removing junk words in tf-idf generation for specific usecases\n",
    "\n",
    "NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoS on cleaned text\n",
      "[('people', 'NNS'), ('like', 'IN'), ('see', 'NN'), ('sachin', 'JJ'), ('play', 'VB'), ('it', 'PRP'), ('always', 'RB'), ('gets', 'VBZ'), ('interested', 'JJ'), ('cricket', 'NN'), ('it', 'PRP'), ('good', 'JJ'), ('see', 'NN'), ('people', 'NNS'), ('show', 'VBP'), ('interest', 'NN'), ('they', 'PRP'), ('love', 'VBP'), ('sachin', 'NN'), ('he', 'PRP'), ('given', 'VBN'), ('much', 'JJ'), ('game', 'NN'), ('his', 'PRP$'), ('strokes', 'NNS'), ('mrf', 'VBP'), ('bat', 'NN'), ('etched', 'VBN'), ('people', 'NNS'), ('memoris', 'VBP'), ('many', 'JJ'), ('current', 'JJ'), ('cricketers', 'NNS'), ('owe', 'VBP'), ('pursuing', 'VBG'), ('cricket', 'NN')]\n",
      "PoS on raw text\n",
      "[('People', 'NNS'), ('like', 'IN'), ('to', 'TO'), ('see', 'VB'), ('Sachin', 'NNP'), ('play', 'NN'), ('.', '.'), ('It', 'PRP'), ('always', 'RB'), ('gets', 'VBZ'), ('them', 'PRP'), ('interested', 'JJ'), ('in', 'IN'), ('Cricket', 'NN'), ('!', '.'), ('It', 'PRP'), (\"'s\", 'VBZ'), ('good', 'JJ'), ('to', 'TO'), ('see', 'VB'), ('people', 'NNS'), ('show', 'VBP'), ('such', 'JJ'), ('interest', 'NN'), ('.', '.'), ('They', 'PRP'), ('love', 'VBP'), ('Sachin', 'NNP'), ('.', '.'), ('He', 'PRP'), ('has', 'VBZ'), ('given', 'VBN'), ('so', 'RB'), ('much', 'JJ'), ('to', 'TO'), ('the', 'DT'), ('game', 'NN'), ('.', '.'), ('His', 'PRP$'), ('strokes', 'NNS'), ('with', 'IN'), ('his', 'PRP$'), ('MRF', 'NNP'), ('bat', 'NN'), ('are', 'VBP'), ('etched', 'VBN'), ('in', 'IN'), ('people', 'NNS'), (\"'s\", 'POS'), ('memoris', 'NN'), ('.', '.'), ('Many', 'JJ'), ('current', 'JJ'), ('cricketers', 'NNS'), ('owe', 'VBP'), ('pursuing', 'VBG'), ('cricket', 'NN'), ('to', 'TO'), ('him', 'PRP'), ('.', '.')]\n",
      "NER on raw text\n",
      "Tree('S', [('People', 'NNS'), ('like', 'IN'), ('to', 'TO'), ('see', 'VB'), Tree('PERSON', [('Sachin', 'NNP')]), ('play', 'NN'), ('.', '.'), ('It', 'PRP'), ('always', 'RB'), ('gets', 'VBZ'), ('them', 'PRP'), ('interested', 'JJ'), ('in', 'IN'), Tree('GPE', [('Cricket', 'NN')]), ('!', '.'), ('It', 'PRP'), (\"'s\", 'VBZ'), ('good', 'JJ'), ('to', 'TO'), ('see', 'VB'), ('people', 'NNS'), ('show', 'VBP'), ('such', 'JJ'), ('interest', 'NN'), ('.', '.'), ('They', 'PRP'), ('love', 'VBP'), Tree('PERSON', [('Sachin', 'NNP')]), ('.', '.'), ('He', 'PRP'), ('has', 'VBZ'), ('given', 'VBN'), ('so', 'RB'), ('much', 'JJ'), ('to', 'TO'), ('the', 'DT'), ('game', 'NN'), ('.', '.'), ('His', 'PRP$'), ('strokes', 'NNS'), ('with', 'IN'), ('his', 'PRP$'), Tree('ORGANIZATION', [('MRF', 'NNP')]), ('bat', 'NN'), ('are', 'VBP'), ('etched', 'VBN'), ('in', 'IN'), ('people', 'NNS'), (\"'s\", 'POS'), ('memoris', 'NN'), ('.', '.'), ('Many', 'JJ'), ('current', 'JJ'), ('cricketers', 'NNS'), ('owe', 'VBP'), ('pursuing', 'VBG'), ('cricket', 'NN'), ('to', 'TO'), ('him', 'PRP'), ('.', '.')])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "tagged_words = pos_tag(words)\n",
    "print(\"PoS on cleaned text\")\n",
    "print(tagged_words)\n",
    "tagged_text = pos_tag(word_tokens)\n",
    "print(\"PoS on raw text\")\n",
    "print(tagged_text)\n",
    "\n",
    "#Identify named entities\n",
    "#processed_words = [list(word)[0] for word in lemmatized_words ]\n",
    "entities = nltk.chunk.ne_chunk(tagged_text)\n",
    "print(\"NER on raw text\")\n",
    "print(entities.__repr__())\n",
    "\n",
    "filtered_tagged_text = [w for w in tagged_text if not list(w)[0] in stop_words]\n",
    "#print(filtered_text)\n",
    "\n",
    "#for w in filtered_tagged_text:\n",
    "#    if(list(w)[0].isalpha()):\n",
    "#        print(list(w)[0].lower())\n",
    "\n",
    "tagged_words = [[list(w)[0].lower(), list(w)[1]] for w in filtered_tagged_text if list(w)[0].isalpha()]\n",
    "#print(tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spell Correction\n",
    "\n",
    "Should eliminate NER entities from spell corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "caesar\n",
      "car\n"
     ]
    }
   ],
   "source": [
    "from autocorrect import spell\n",
    "import re\n",
    "\n",
    "print(spell('hte'))\n",
    "print(spell('caaaar'))\n",
    "print(spell(re.sub(r'(.)\\1+', r'\\1\\1', \"caaaar\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['people', 'NNS'], ['like', 'IN'], ['see', 'VB'], ['machin', 'NNP'], ['play', 'NN'], ['it', 'PRP'], ['always', 'RB'], ['gets', 'VBZ'], ['interested', 'JJ'], ['cricket', 'NN'], ['it', 'PRP'], ['good', 'JJ'], ['see', 'VB'], ['people', 'NNS'], ['show', 'VBP'], ['interest', 'NN'], ['they', 'PRP'], ['love', 'VBP'], ['machin', 'NNP'], ['he', 'PRP'], ['given', 'VBN'], ['much', 'JJ'], ['game', 'NN'], ['his', 'PRP$'], ['strokes', 'NNS'], ['MRF', 'NNP'], ['bat', 'NN'], ['etched', 'VBN'], ['people', 'NNS'], ['memories', 'NN'], ['many', 'JJ'], ['current', 'JJ'], ['cricketers', 'NNS'], ['owe', 'VBP'], ['pursuing', 'VBG'], ['cricket', 'NN']]\n"
     ]
    }
   ],
   "source": [
    "spell_corrected = [[spell(re.sub(r'(.)\\1+', r'\\1\\1', list(w)[0])), list(w)[1]] for w in tagged_words]\n",
    "print(spell_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['people', 'NNS'], ['like', 'IN'], ['see', 'VB'], ['machin', 'NNP'], ['play', 'NN'], ['it', 'PRP'], ['always', 'RB'], ['get', 'VBZ'], ['interested', 'JJ'], ['cricket', 'NN'], ['it', 'PRP'], ['good', 'JJ'], ['see', 'VB'], ['people', 'NNS'], ['show', 'VBP'], ['interest', 'NN'], ['they', 'PRP'], ['love', 'VBP'], ['machin', 'NNP'], ['he', 'PRP'], ['give', 'VBN'], ['much', 'JJ'], ['game', 'NN'], ['his', 'PRP$'], ['stroke', 'NNS'], ['MRF', 'NNP'], ['bat', 'NN'], ['etch', 'VBN'], ['people', 'NNS'], ['memory', 'NN'], ['many', 'JJ'], ['current', 'JJ'], ['cricketer', 'NNS'], ['owe', 'VBP'], ['pursue', 'VBG'], ['cricket', 'NN']]\n",
      "['people', 'like', 'see', 'sachin', 'play', 'it', 'always', 'get', 'interested', 'cricket', 'it', 'good', 'see', 'people', 'show', 'interest', 'they', 'love', 'sachin', 'he', 'given', 'much', 'game', 'his', 'stroke', 'mrf', 'bat', 'etched', 'people', 'memoris', 'many', 'current', 'cricketer', 'owe', 'pursuing', 'cricket']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#for w in tagged_words:\n",
    "#    print(w)\n",
    "#    print(get_wordnet_pos(list(w)[1]))\n",
    "#    print(lemmatizer.lemmatize(list(w)[0], get_wordnet_pos(list(w)[1])))\n",
    "\n",
    "lemmatized_words = [[lemmatizer.lemmatize(list(w)[0], get_wordnet_pos(list(w)[1])), list(w)[1]] for w in spell_corrected]\n",
    "print(lemmatized_words)\n",
    "\n",
    "lemmatized_without_pos = [lemmatizer.lemmatize(word) for word in words]\n",
    "print(lemmatized_without_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['peopl', 'like', 'see', 'machin', 'play', 'it', 'alway', 'get', 'interest', 'cricket', 'it', 'good', 'see', 'peopl', 'show', 'interest', 'they', 'love', 'machin', 'he', 'given', 'much', 'game', 'hi', 'stroke', 'mrf', 'bat', 'etch', 'peopl', 'memori', 'mani', 'current', 'cricket', 'owe', 'pursu', 'cricket']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "\n",
    "stemmed_words = [st.stem(list(word)[0]) for word in spell_corrected]\n",
    "print(stemmed_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
